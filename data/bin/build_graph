#!/usr/bin/env python

import click
import numpy as np
import os
import json

from collections import OrderedDict
from textplot.utils import sort_dict
from textplot.text import Text
from textplot.matrix import Matrix
from humanist.graphs import Diachronic


@click.command()
@click.option('--freq_depth',   default=3000)
@click.option('--spike_depth',  default=1000)
@click.option('--skim_depth',   default=5)
@click.option('--bandwidth',    default=100000)
def build_graph(freq_depth, spike_depth, skim_depth, bandwidth):

    if not os.path.exists('build/kde'):
        os.makedirs('build/kde')

    print 'Tokenizing corpus...'
    t = Text.from_file('corpus.txt')
    m = Matrix(t)

    # Get the top X most frequent terms.
    frequent = t.most_frequent_terms(freq_depth)

    print 'Computing standard deviations...'
    spiky = OrderedDict()
    for term in frequent:
        spiky[term] = np.std(t.terms[term])

    # Sort by KDE max.
    spiky = sort_dict(spiky, False)
    terms = spiky.keys()[:spike_depth]

    print 'Indexing terms:'
    m.index(terms, bandwidth=bandwidth)

    g = Diachronic()

    print 'Generating graph:'
    g.build(m, skim_depth, bandwidth=bandwidth)
    g.write_gml('build/graph.gml')

    # Write the KDEs.
    for term in terms:

        # Compute the KDE.
        kde = t.kde(term, bandwidth=bandwidth, samples=100)
        kde = [{'value': v} for v in kde.tolist()]
        out = 'build/kde/'+t.unstem(term)+'.json'

        # Write the file.
        with open(out, 'w') as f:
            f.write(json.dumps(kde))
            print out


if __name__ == '__main__':
    build_graph()
